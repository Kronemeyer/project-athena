{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minerva - Task 2 Report: Hybrid ATHENA\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract \n",
    "\n",
    "In Task Two, we built Hybrid ensembles from the library of diverse types of weak defenses. By randomly selecting a combination of 20 different CNNs and SVMs weak defences, we ran Basic Iterative Method (BIM), Carlini - Wagner (CW), and Projected Gradient Descent (PGD) attacks against 10 different sets of Hybrid ensembles on various machines’ hardware. Our experiment has shown that an ensemble with a ratio of more CNNs than SVMs yielded the most effective attacks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "For this experiment, we chose to modify the evaluation algorithm to randomly choose 20 different weak defences with variants of CNNs and SVMs. These defences were tested against the Basic Iterative Method (BIM), Carlini - Wagner (CW), and Projected Gradient Descent (PGD) attacks. Each of the 20 variants were run 10 times on various hardware to ensure the validity of the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "**A Convolutional Neural Network** (CNN) is an algorithm that helps machine learning differentiate images, speech, etc via the 2D structures of the input. The architecture of CNN's include a number of convolutional and subsampling layers which may, or may not, be followed by other fully connected neural network layers. CNNs achieve their layers through the use of various filters, called kernels, that slide across the original image in a window size, n x n x q (in which n is smaller than the dimensions of the image and q equal to or smaller than the number of available channels within the image). [\\[4\\]](http://deeplearning.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/)  \n",
    "\n",
    "**A Support Vector Machine** (SVM) is an algorithm that attempts to find the best hyperplane between input vectors when training a machine learning system with the correct input. [\\[5\\]](https://iopscience.iop.org/article/10.1088/1755-1315/357/1/012035/pdf)\n",
    "\n",
    "**The Carlini - Wagner attack** (CW) includes three possible distance metrics L<sub>0</sub>, L<sub>2</sub>, and L<sub>∞</sub>. L<sub>0</sub> corresponds to how many pixels have been altered in an image, L<sub>2</sub> measures the standard Euclidean distance between pixels that have been altered, and L<sub>∞</sub> measures the maximum change to any of the coordinates within the image following the following maximization:\n",
    "<p style=\"text-align: center;\"> || x - x' ||<sub>∞</sub> = max(|x<sub>1</sub>-x'<sub>1</sub>|,...,|x<sub>n</sub> - x'<sub>n</sub>|)</p>\n",
    "\n",
    "\n",
    "[\\[1\\]](https://arxiv.org/pdf/1608.04644.pdf)  \n",
    "In other words, the image has a maximum budget allowed but may have as many pixel changes as needed to meet that budget. The specific iteration that CW implements for their L<sub>∞</sub> attacks solve the minimization for\n",
    "<p style=\"text-align: center;\"> min c • ƒ(x + δ) + Σ<sub>i</sub>[(δ<sub>i</sub>-τ)<sup>+</sup>]</p><br>\n",
    "\n",
    "where τ is a correction to prevent oscillation in suboptimal solutions and c is the smallest value which results in which ƒ(x<sup>*</sup>) ≤ 0 <a href=\"https://arxiv.org/pdf/1608.04644.pdf\">[1]</a>\n",
    "\n",
    "<!--[[1]](https://arxiv.org/pdf/1608.04644.pdf)-->  \n",
    "\n",
    "\n",
    "**The Basic Iterative Method** (BIM) is an extension of the Fast Gradiant (FGSM) method to produce adversarial attacks that introduced an iterative step in which the FGSM perturbations are applied multiple times in small steps and then pixel values of intermediate results are clipped after each step to ensure the resulting image is in an acceptible range of the original image <a href=\"https://arxiv.org/pdf/1607.02533.pdf\">[2]</a>. This is mathematically represented as such\n",
    "\n",
    "<!--[[2]](https://arxiv.org/pdf/1607.02533.pdf) -->\n",
    "\n",
    "<p style=\"text-align: center;\">X<sub>0</sub><sup>adv</sup> = X, X<sub>N+1</sub><sup>adv</sup> = Clip<sub>X,ε</sub> {X<sub>N</sub><sup>adv</sup> + α sign (∇<sub>X</sub>J(X<sub>N</sub><sup>adv</sup>, Y<sub>true</sub>)) } </p>\n",
    "\n",
    "Where, X is the image and X<sup>adv</sup> is the adversarial image, Y<sub>true</sub> is the true class for X, J(X,y) is the cross-entropy cost functionof the neural network without the network weights and parameters, and Clip<sub>X,ε</sub> {X'} is the function that performs the per-pixel clipping to keep the image in the L<sub>inf</sub> neighborhood of the original image [\\[2\\]](https://arxiv.org/pdf/1607.02533.pdf).\n",
    "\n",
    "    \n",
    "**The Projected Gradient Descent** (PGD) method is also a multi-step variant of the FGSM in which the negative loss function is used to create an adversarial image:\n",
    "\n",
    "<p style=\"text-align: center;\">x<sup>t+1</sup> = Π<sub>x+S</sub>(x<sup>t</sup> + α sign (∇<sub>x</sub> L(0,x,y)))</p>   \n",
    "\n",
    "[\\[3\\]](https://arxiv.org/pdf/1706.06083.pdf)\n",
    "\n",
    "For our experiment, our goal is to determine the effectiveness of these three types of attacks againsts an Athena ensemble composed of the first 20 wd's. To do this, the adversarial examples are constructed by manipulating the tunable parameters within the attacks and then evaluated one by one on the Athena ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental settings \n",
    "\n",
    "#### Basic Iterative Method (BIM) Attacks\n",
    "\n",
    "The BIM Attacks are varied by epsilon strengths as used in our previous experiment. They increased by 20%. As the CNNs in the variants increase, the effectiveness of the attack increases. \n",
    "\n",
    "Specific Epsilon values use: 0.01, 0.05, 0.10, 0.15, 0.20\n",
    "\n",
    "Note: the attack settings are too small for the undefended model to be fooled for the .01 and .05 epsilon. These settings were from our first attack settings and due to the length of time it takes to redo everything we cannot change them now.\n",
    "\n",
    "#### Carlini - Wagner (CW) Attacks\n",
    "\n",
    "Similar to our first experiment we chose to use the Linf configuration for the CW attacks. We held one variable as a constant and gradually increased the strength of the other variable. Just like the BIM attack, the effectiveness increased with the increase of CNNs to SVMs.\n",
    "\n",
    "Specific Epsilons used for constant LW value: 0.2, 0.4, 0.6, 0.8\n",
    "\n",
    "Specific LW used for constant epsilon value: 0.2, 0.4, 0.6, 0.8\n",
    "\n",
    "#### Projected Gradient Descent (PGD) Attacks\n",
    "\n",
    "The PGD Attacks are also varied by epsilon strengths. It follows the trends in the BIM and CW attacks, where the greater ratio of CNNs to SVMs increase attack efficiency. \n",
    "\n",
    "Specific epsilon values used: 0.05, 0.075, 0.10, 0.15, 0.25\n",
    "\n",
    "Note: the attack settings are too small for the undefended model to be fooled for the .05 and .075 epsilon. These settings were from our first attack settings and due to the length of time it takes to redo everything we cannot change them now.\n",
    "\n",
    "#### Code \n",
    "\n",
    "To generate your own results, the rand_eval_model python file in the scripts directory can be ran from the terminal. The required input parameters include:\n",
    "* The transformation config file for athena wd's\n",
    "* The transformation config file for the svm mnists\n",
    "* The model configs for the hybrid-mnists\n",
    "* The images to pass to the models to determine effectiveness\n",
    "\n",
    "Examples of these can be found in the configs/ data/ and models/ directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machines Used\n",
    "\n",
    "During this experiment, we utilized several different machines to conclude our results. \n",
    "\n",
    "- i7-9700k with 16GB of Ram\n",
    "- Laptop i7-10510U with 12GB of Ram\n",
    "- i7-MacBook Pro with 16GB of Ram\n",
    "- Laptop i5-8350u with 16GB of Ram \n",
    "- Desktop Ryzen 3600 with 16GB of Ram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "After finishing our testing we had 50 tests with the first 27 tests having more SVMs than CNNs, the 28th test having an even amount, and the last 22 having more CNNs than SVMs as shown in figure 1.1. According to our median error rate graph the PGD-ADT had a better error rate until we had a larger portion of CNNs than SVMs. This leads us to believe that using the SVMs with the particular AE’s that we used is not beneficial. \n",
    "\n",
    "With every AE the results were the same as the median showing an increased performance with a larger amount of CNNs. \n",
    "\n",
    "While testing we tracked the amount of time it took to finish all the tests. We did not see any real correlation with the ratio of CNNs and SVMs according to our data. We also used six different sets of hardware for the tests so the data might not be the most accurate / precise. It can be noted though that some of the faster CPUs being used still netted the longer times so that might not be as large of a factor.\n",
    "\n",
    "When looking at the BIM .01 epsilon and the PGD .025 epsilon the jump in error rate is most likely due to the weak defenses over analyzing the largely unperturbed data which the undefended model would not do. All had the 67th config in common in the athena-mnist.json file. This is a denoise_nl_means defense. The other denoise type CNNs did not have the same detrimental effect according to our other results but there may be other factors at play as well. \n",
    "\n",
    "#### Future Possible Tests:\n",
    "\n",
    "The team discussed multiple possible methods that would be interesting to implement for this task given more time to complete them.\n",
    "\n",
    "1) A genetic algorithm where in x tests were randomly selected y times and the tests that generated the best results from each batch were grouped together for a third run, hopefully ensuring the lowest possible error rate.\n",
    "\n",
    "2) Randomizing defenses in such a way that defenses were randomly selected but no more than one defense was selected from each “group”  of defenses (affine, augment, cartoon, compress, denoise, distort, filter, flip, morph, noise, quant, rotate, seg, shift, geo)\n",
    "\n",
    "#### Other Considerations:\n",
    "\n",
    "3) Through our testing we’ve found that it’s possible that the accuracy and speed of the weak defenses varies, in some cases by a large amount. It appears that some of the SVM defenses took far longer than the CNN counterparts. Given more time some research could be done to find the optimal ratio between speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The graph below illustrates the time taken in minutes to execute each test and is arranged from the lowest ratio of CNNs to SVMs to the highest ratio of CNNs to SVMs.\n",
    "\n",
    "<br>\n",
    "\n",
    "![AvgTimeinMin](Img/AvgTimeinMin.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.0 Average Time per minute per test; arranged from lowest to highest CNN to SVM Ratio.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "This graph shows the median of the error rates of Adversarial Examples attacks from the lowest to highest CNN to SVM ratio. The AE attack performance increase with a higher amount of CNNs. Test 29 shows where there are the same amount of CNNs and SVMs where after that it shows more CNNs. \n",
    "\n",
    "![median_graph](Img/median_graph.jpg)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.1 The Median Error Rates from Lowest to Highest CNN to SVM Ratio.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "*Undefended Model*\n",
    "\n",
    "The graph below displays the average of effectiveness from each of the test ran during this experiment without an Undefended Model. Attacks with greater CNNs exhibit better performance.\n",
    "\n",
    "![AvgEffwithoutUM](Img/AvgEffwithoutUM.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.2 Average Effectiveness of Attacks without Undefended Model.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "The graph below displays the average of effectiveness from each of the test ran during this experiment with an Undefended Model. The results are similar to the previous graph save for the performace of the Undefended Model where the error rate fluctuates.\n",
    "\n",
    "![AvgEffwithUM](Img/AvgEffwithUM.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.3 Average Effectiveness of Attacks with Undefended Model.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "*BIM Attacks*\n",
    "\n",
    "This graph describes the effectiveness of the BIM attacks with increasing CNN to SVM ratio. As the number of CNNs increase the efficiency of the attack increases which means the error rate decreases. The greatest effectiveness is achieved with an epsilon of 0.05.\n",
    "\n",
    "The duplicate labels come from a different result with the same amount of CNNs and SVMs.\n",
    "\n",
    "![BIMAttacks](Img/BIMAttacks.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.4 BIM Attacks with Increasing CNN to SVM Ratio.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "*CW Attacks*\n",
    "\n",
    "This graph illustrates the effectiveness of the CW attacks with a constant epsilon value of 0.1 and increasing LW value. Consistant with previous test, the greater the CNN value the better the performance. The most effective CW attack provided the lowest error rate, an epsilon value of 0.1, and an LW value of 0.2.\n",
    "\n",
    "The duplicate labels come from a different result with the same amount of CNNs and SVMs.\n",
    "\n",
    "![CWAttacksConstEps](Img/CWAttacksConstEps.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.5 CW Attacks with a Constant Epsilon and Increasing CNN to SVM Ratio.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "This graph shows the effectiveness of the CW attacks with a constant LW value of 0.1 and increasing epsilon value. Like the graph above, the increase in the CNN value resulted in a better attack performance. The most effective CW attack provided the lowest error rate, an epsilon value of 0.2, and an LW value of 0.1.\n",
    "\n",
    "The duplicate labels come from a different result with the same amount of CNNs and SVMs.\n",
    "\n",
    "![CWAttacksConstLW](Img/CWAttacksConstLW.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.6 CW Attacks with Constant LW and Increasing CNN to SVM Ratio.</em>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "*PGD Attacks*\n",
    "\n",
    "The graph below displays the efficiency of the PGD attack with increasing CNN to SVM ratio. The error rate decreases as the CNN ratio to SVM increases. The most efficient PGD attack consists of an epsilon value of 0.10. \n",
    "\n",
    "The duplicate labels come from a different result with the same amount of CNNs and SVMs.\n",
    "\n",
    "\n",
    "![PGDAttacks](Img/PGDAttacks.png)\n",
    "<div style=\"text-align: center\">\n",
    "    <em>Figure 1.7 PGD Attacks with Increasing CNN to SVM Ratio.</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Contribution\n",
    "\n",
    "This task would not have been possible without contribution from each team member. All members contributed to coding, testing, and reporting. Please note that while not everyone has commits in GitHub we collaborated over Discord and shared code there and just had a single person commit so we all had the same exact code. The most crucial, and time dependent, section of this project was the testing. Each member helped to generate multiple test results (in some cases multiple computers were running tests for each member) to ensure the maximum amount of test data was generated for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion, an ensemble with a greater ratio of CNNs vs SVMs generates improved attack efficiency when we construct a series of hybrid ensembles through the library of diverse types of weak defenses. We deduced our findings from an experiment where we processed 10 sets of varying combinations of Hybrid ensembles with randomly selected combinations of 20 various SVMs and CNNs weak defenses with the goal of finding the most effective attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\\[1\\] Carlini, B., Wagner, D. Towards Evaluating the Robustness of Neural Networks. arXiv reprint arXiv:1608.04644 (2017)  \n",
    "\\[2\\] Kurakin, A., Goodfellow, I., Bengio, S. Adversarial Examples in the Physical World arXiv reprint arXiv:1607.02533 (2017)  \n",
    "\\[3\\] Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A. Towards Deep Learning Models Resistant to Adversarial Attacks. arXiv reprint arXiv:1706.06083 (2019)  \n",
    "\\[4\\] “Convolutional Neural Network,” Unsupervised Feature Learning and Deep Learning Tutorial. [Online]. Available: http://deeplearning.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/. [Accessed: 28-Nov-2020]. \n",
    "\\[5\\] Hayder Hasan et al 2019 IOP Conf. Ser.: Earth Environ. Sci. 357 012035 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
